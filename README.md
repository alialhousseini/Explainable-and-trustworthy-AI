# Explainable-and-trustworthy-AI
This repository collects all the material related to the Explainable and trustworthy AI Course.

# Table of Contents
- [Course Description](#course-description)
- [Laboratories](#laboratories)
- [Projects Proposal](#project-proposal)


## Course Description

Understanding a model inner workings and the reasons for its decisions is important to establish trust in the outcome of a machine learning process. However, many machine learning models (e.g., deep learning models) do not disclose their internal logic producing the prediction and for this reason are denoted as "black-box models". Explainability of a model, in its many facets, contributes to the robustness and reliability of any machine learning application. It provides support in most phases that lead from design to deployment of ML applications, ranging from model validation and testing, to model debugging and audit. Furthermore, explaining the outcome of ML algorithms can help end users both in understanding the reason for a decision and in trusting the model outcome.

The course, elective for the Master in Computer Engineering and in Data Science and Engineering, will cover explanation methods for both predictive and explorative ML algorithms, with a specific attention to their exploitation in deployed machine learning frameworks. Experimental activities in lab will allow the practical evaluation of the presented explanation methods on real-world datasets, considering both the ML developer and final user perspectives.

## Laboratories

## Projects Proposal

### Project 1: 

### Project 2: